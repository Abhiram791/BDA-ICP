{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhiram791/BDA-ICP/blob/main/abhiram_700773914_ipynb(6).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1**\n",
        "\n",
        "Activation: ReLU\n",
        "\n",
        "Optimizer: Adam\n",
        "\n",
        "Neurons: [128, 256, 512, 256, 128,10]\n",
        "\n",
        "Dataset: MNIST\n",
        "\n",
        "Epochs: 10\n",
        "\n",
        "Batch Size: 32"
      ],
      "metadata": {
        "id": "FTQzVfFoGi-V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laTHQ-oR4Fvf",
        "outputId": "0101663f-34c5-440c-9d84-dcddcb594433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8626 - loss: 0.4418 - val_accuracy: 0.9592 - val_loss: 0.1422\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.1323 - val_accuracy: 0.9662 - val_loss: 0.1213\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9722 - loss: 0.0953 - val_accuracy: 0.9707 - val_loss: 0.1080\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9788 - loss: 0.0728 - val_accuracy: 0.9707 - val_loss: 0.1110\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9819 - loss: 0.0619 - val_accuracy: 0.9682 - val_loss: 0.1173\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.0522 - val_accuracy: 0.9746 - val_loss: 0.1018\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0445 - val_accuracy: 0.9722 - val_loss: 0.1303\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0381 - val_accuracy: 0.9726 - val_loss: 0.1149\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0321 - val_accuracy: 0.9725 - val_loss: 0.1152\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0293 - val_accuracy: 0.9782 - val_loss: 0.1087\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9724 - loss: 0.1131\n",
            "Test Accuracy: 98%\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc * 100:.0f}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v-KK3zQ-GwQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment - 2:\n",
        "\n",
        "Activation: Tanh\n",
        "\n",
        "Optimizer: SGD\n",
        "\n",
        "Neurons: [256, 512, 1024, 512, 256,10]\n",
        "\n",
        "Dataset: MNIST\n",
        "\n",
        "Epochs: 10\n",
        "\n",
        "Batch Size: 32"
      ],
      "metadata": {
        "id": "HvE75pFCIbiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(256, activation='tanh'))\n",
        "model.add(Dense(512, activation='tanh'))\n",
        "model.add(Dense(1024, activation='tanh'))\n",
        "model.add(Dense(512, activation='tanh'))\n",
        "model.add(Dense(256, activation='tanh'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Experiment 2 - Test Accuracy: {test_acc * 100:.0f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UvwcIiuGvzu",
        "outputId": "6c35532e-ba68-4453-cff9-311764cd56f5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8554 - loss: 0.4590 - val_accuracy: 0.9312 - val_loss: 0.2189\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9515 - loss: 0.1591 - val_accuracy: 0.9582 - val_loss: 0.1436\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.1073 - val_accuracy: 0.9670 - val_loss: 0.1072\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9779 - loss: 0.0721 - val_accuracy: 0.9658 - val_loss: 0.1128\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.0556 - val_accuracy: 0.9714 - val_loss: 0.1049\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.0433 - val_accuracy: 0.9732 - val_loss: 0.0909\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0323 - val_accuracy: 0.9732 - val_loss: 0.1010\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0235 - val_accuracy: 0.9733 - val_loss: 0.0972\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0175 - val_accuracy: 0.9737 - val_loss: 0.0935\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9974 - loss: 0.0110 - val_accuracy: 0.9748 - val_loss: 0.0961\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9708 - loss: 0.1001\n",
            "Experiment 2 - Test Accuracy: 98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment - 3\n",
        "\n",
        "Activation: Sigmoid\n",
        "\n",
        "Optimizer: RMSprop\n",
        "\n",
        "Neurons: [64, 128, 256, 128, 64,10]\n",
        "\n",
        "Dataset: MNIST\n",
        "\n",
        "Epochs: 10\n",
        "\n",
        "Batch Size: 32"
      ],
      "metadata": {
        "id": "4ExGiZEQIvp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(64, activation='sigmoid'))\n",
        "model.add(Dense(128, activation='sigmoid'))\n",
        "model.add(Dense(256, activation='sigmoid'))\n",
        "model.add(Dense(128, activation='sigmoid'))\n",
        "model.add(Dense(64, activation='sigmoid'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Experiment 3 - Test Accuracy: {test_acc * 100:.0f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ycm9wXOuHrxP",
        "outputId": "d7097cd8-46e0-4e88-d325-a65f928c6d47"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1766 - loss: 2.1198 - val_accuracy: 0.5218 - val_loss: 1.1833\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6465 - loss: 0.9592 - val_accuracy: 0.8284 - val_loss: 0.5392\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8589 - loss: 0.4770 - val_accuracy: 0.9168 - val_loss: 0.2915\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9150 - loss: 0.3011 - val_accuracy: 0.9274 - val_loss: 0.2576\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.2308 - val_accuracy: 0.9317 - val_loss: 0.2346\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9447 - loss: 0.1977 - val_accuracy: 0.9496 - val_loss: 0.1733\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9511 - loss: 0.1702 - val_accuracy: 0.9449 - val_loss: 0.1890\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1551 - val_accuracy: 0.9554 - val_loss: 0.1562\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1396 - val_accuracy: 0.9541 - val_loss: 0.1647\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1305 - val_accuracy: 0.9552 - val_loss: 0.1598\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9489 - loss: 0.2059\n",
            "Experiment 3 - Test Accuracy: 96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment - 4\n",
        "\n",
        "Activation: ReLU\n",
        "\n",
        "Optimizer: SGD\n",
        "\n",
        "Neurons: [32, 64, 128, 64, 32,10]\n",
        "\n",
        "Dataset: MNIST\n",
        "\n",
        "Epochs: 10\n",
        "\n",
        "Batch Size: 32"
      ],
      "metadata": {
        "id": "gyi1VzbzI67x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Experiment 4 - Test Accuracy: {test_acc * 100:.0f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPCG4mjEH_Ka",
        "outputId": "52e7ebb4-eb15-4aa6-c9cb-32fbcb9146ca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 0.8217 - val_accuracy: 0.9399 - val_loss: 0.2054\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9431 - loss: 0.1900 - val_accuracy: 0.9543 - val_loss: 0.1525\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1424 - val_accuracy: 0.9627 - val_loss: 0.1301\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.1184 - val_accuracy: 0.9551 - val_loss: 0.1557\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9668 - loss: 0.1054 - val_accuracy: 0.9586 - val_loss: 0.1534\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9715 - loss: 0.0932 - val_accuracy: 0.9658 - val_loss: 0.1236\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.0769 - val_accuracy: 0.9618 - val_loss: 0.1440\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9789 - loss: 0.0713 - val_accuracy: 0.9684 - val_loss: 0.1122\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9800 - loss: 0.0639 - val_accuracy: 0.9679 - val_loss: 0.1193\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9797 - loss: 0.0620 - val_accuracy: 0.9687 - val_loss: 0.1290\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.1398\n",
            "Experiment 4 - Test Accuracy: 97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment - 5\n",
        "\n",
        "Activation: Tanh\n",
        "\n",
        "Optimizer: Adam\n",
        "\n",
        "Neurons: [128, 128, 128, 128, 128,10]\n",
        "\n",
        "Dataset: MNIST\n",
        "\n",
        "Epochs: 10\n",
        "\n",
        "Batch Size: 32"
      ],
      "metadata": {
        "id": "4SfTljjXJKhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(128, activation='tanh'))\n",
        "model.add(Dense(128, activation='tanh'))\n",
        "model.add(Dense(128, activation='tanh'))\n",
        "model.add(Dense(128, activation='tanh'))\n",
        "model.add(Dense(128, activation='tanh'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Experiment 5 - Test Accuracy: {test_acc * 100:.0f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1nMOAgEIphO",
        "outputId": "87d40f9a-aa52-4ed2-bade-53df470f2244"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8694 - loss: 0.4326 - val_accuracy: 0.9525 - val_loss: 0.1625\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1443 - val_accuracy: 0.9617 - val_loss: 0.1352\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9690 - loss: 0.1028 - val_accuracy: 0.9663 - val_loss: 0.1150\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.0824 - val_accuracy: 0.9672 - val_loss: 0.1098\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.0618 - val_accuracy: 0.9679 - val_loss: 0.1109\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9846 - loss: 0.0502 - val_accuracy: 0.9707 - val_loss: 0.1124\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.0458 - val_accuracy: 0.9691 - val_loss: 0.1175\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0363 - val_accuracy: 0.9714 - val_loss: 0.1139\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9899 - loss: 0.0316 - val_accuracy: 0.9668 - val_loss: 0.1292\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0295 - val_accuracy: 0.9690 - val_loss: 0.1253\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9624 - loss: 0.1406\n",
            "Experiment 5 - Test Accuracy: 97%\n"
          ]
        }
      ]
    }
  ]
}